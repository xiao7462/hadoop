# linux 下创建 hadoop用户
```bash
sudo useradd -m hadoop -s /bin/bash  #创建hadoop用户，并使用/bin/bash作为shell
sudo passwd hadoop                   #为hadoop用户设置密码，之后需要连续输入两次密码
sudo adduser hadoop sudo             #为hadoop用户增加管理员权限
su - hadoop                          #切换当前用户为用户hadoop
sudo apt-get update                  #更新hadoop用户的apt,方便后面的安装

#   hadoop 账户报错  xxxis not in the sudoers file. This incident will be reported.
# 
#1.切换到root用户下 
#　　方法为直接在命令行输入：su，然后输入密码（即你的登录密码，且密码默认不可见）。

#2./etc/sudoers文件默认是只读的，对root来说也是，因此需先添加sudoers文件的写权限,命令是: 
#即执行操作：chmod u+w /etc/sudoers

#3.编辑sudoers文件 
#即执行：vi /etc/sudoers 
#找到这行 root ALL=(ALL) ALL,在他下面添加xxx ALL=(ALL：ALL) ALL (这里的xxx是你的用户名)
#4.撤销sudoers文件写权限,命令: 
#chmod u-w /etc/sudoers
```



# hadoop的安装与环境配置

##  先卸载原有的 JDK
`sudo apt-get remove openjdk*  `

## 安装hadoop和JDK
## 安装JDK 
下载jdk后放置在 `/software` 目录下
`tar -zxvf java-jdk*****.jar`
配置环境 `vim ~/.bashrc`
```bash
#在文件最后添加
export JAVA_HOME=/home/hadoop/software/jdk1.8.0_144
export PATH=$PATH:$JAVA_HOME/bin
#刷新配置
source ~/.bashrc
```
检查是否安装成功 `java -version`

## 安装hadoop
hadoop放置在`/module`中
添加hadoop环境
```bash
##HADOOP_HOME
export HADOOP_HOME=/home/hadoop/module/hadoop-2.7.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

```
输入 `hadoop`  查看是否安装成功


# Standalone Operation 模式
在hadoop目录下执行
```bash
mkdir input
cp etc/hadoop/*.xml input
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar grep input output 'dfs[a-z.]+'  #hadoop-mapreduce-examples-3.1.2.jar 会根据版本不同而修改
cat output/*
```

# WordCount  案例
```bash
mkdir wcinput #创建一个目录
vim wc.input #  在 wcinput 目录下随笔传输一些单词
# 调用hadoop的wordcount程序
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar wordcount wcinput/ wcoutput
# 在wcoutput文件夹种的有  part-r-00000  _SUCCESS
cat part-r-00000 #就可以查看wrodcount#


$ cat part-r-00000
aa      1
gaoyang 1
lihua   1
liwei   1
nvshen  1
qwerr   1
tangxing        3
xiaocheng       1
xinbo   1

```


# 启动与配置 hadoop 
##  修改配置文件
进入`etc/hadoop`   中
* 修改`hadoop-env.sh` 配置 java jdk路径 
 `export JAVA_HOME=/data1/tangx/hadoop/software/jdk1.8.0_144`
* 修改 core-site.xml文件
```bash
<configuration>
    <!-- 指定HDFS老大（namenode）的通信地址 -->
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://locahost:9000</value>
</property>
    <!-- 指定hadoop运行时产生文件的存储路径 -->
<property>
        <name>hadoop.tmp.dir</name>
        <value>/cloud/hadoop/tmp</value>
</property>
</configuration>
```

* 修改hdfs-site.xml，修改配置如下
```bash
<!-- 设置hdfs副本数量 -->
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>
```
* 修改mapred-site.xml 由于在配置文件目录下没有，需要修改名称：mv mapred-site.xml.template mapred-site.xml
```bash
<configuration>
<!-- 通知框架MR使用YARN -->
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
</configuration>

```


* 修改yarn-site.xml，修改内容如下
```bash
<configuration>
<!-- reducer取数据的方式是mapreduce_shuffle -->
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>localhost</value>
</property>
</configuration>

```
## 启动 
* 格式化hadoop
```bash
hadoop namenode -format  （过时）

hdfs namenode -format
```
* 启动hdfs和yarn
```bash
先启动HDFS
sbin/start-dfs.sh

再启动YARN
sbin/start-yarn.sh
```

* 验证 输入`jps` 得到
```bash
45330 SecondaryNameNode
37186 ResourceManager
46755 Jps
46499 NodeManager
40491 DataNode
45037 NameNode

``` 
说明成功    

## 查看网页运行的 hdfs和 mr 的状态
由于连接的服务器没有图形界面，因此用windows的ubuntu远程连接后用浏览器查看
```bash
# hsfs界面
ssh -N -L 50070 :localhost:50070 tangx@XXX
# MR 管理界面
ssh -N -L 8088 :localhost:8088 tangx@XXX
```
![dfsh.png](https://i.loli.net/2019/08/31/sDNf8eVEiIu9mKq.png)

![11.png](https://i.loli.net/2019/08/31/Iot3wMrNlc6B9O7.png)
